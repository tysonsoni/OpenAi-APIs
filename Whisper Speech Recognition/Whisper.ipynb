{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee04e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T11:23:34.374878Z",
     "start_time": "2023-01-01T11:23:09.305022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drpha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f366f766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T11:23:36.210606Z",
     "start_time": "2023-01-01T11:23:34.374878Z"
    }
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798df2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T19:23:31.824670Z",
     "start_time": "2022-12-31T19:23:31.797982Z"
    }
   },
   "outputs": [],
   "source": [
    "youtube_video_url = \"https://www.youtube.com/watch?v=VCLW_nZWyQY\"\n",
    "youtube_video = YouTube(youtube_video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f5dec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T19:23:32.162347Z",
     "start_time": "2022-12-31T19:23:31.831912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIAâ€™s New AI: Paint Like Bob Ross!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_video.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade92852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T19:23:34.238458Z",
     "start_time": "2022-12-31T19:23:32.162347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Stream: itag=\"17\" mime_type=\"video/3gpp\" res=\"144p\" fps=\"7fps\" vcodec=\"mp4v.20.3\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">\n",
      "<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">\n",
      "<Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">\n",
      "<Stream: itag=\"308\" mime_type=\"video/webm\" res=\"1440p\" fps=\"60fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"400\" mime_type=\"video/mp4\" res=\"1440p\" fps=\"60fps\" vcodec=\"av01.0.12M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"299\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"60fps\" vcodec=\"avc1.64002a\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"303\" mime_type=\"video/webm\" res=\"1080p\" fps=\"60fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"399\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"60fps\" vcodec=\"av01.0.09M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"298\" mime_type=\"video/mp4\" res=\"720p\" fps=\"60fps\" vcodec=\"avc1.4d4020\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"302\" mime_type=\"video/webm\" res=\"720p\" fps=\"60fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"398\" mime_type=\"video/mp4\" res=\"720p\" fps=\"60fps\" vcodec=\"av01.0.08M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"397\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"av01.0.04M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"396\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"av01.0.01M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"395\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"av01.0.00M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"394\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"av01.0.00M.08\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n"
     ]
    }
   ],
   "source": [
    "for stream in youtube_video.streams:\n",
    "  print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e420b1b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T19:23:34.441095Z",
     "start_time": "2022-12-31T19:23:34.262467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n"
     ]
    }
   ],
   "source": [
    "for stream in youtube_video.streams.filter(only_audio=True):\n",
    "  print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4fffd0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T19:23:34.607681Z",
     "start_time": "2022-12-31T19:23:34.441095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streams = youtube_video.streams.filter(only_audio=True)\n",
    "stream = streams.first()\n",
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e99d737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-31T19:23:35.176741Z",
     "start_time": "2022-12-31T19:23:34.607681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\drpha\\\\Desktop\\\\Python\\\\OpenAI APIs\\\\Whisper Speech Recognition\\\\2_min_paper_example.mp4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.download(filename='2_min_paper_example.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fb9ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T11:26:13.207493Z",
     "start_time": "2023-01-01T11:23:36.210606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drpha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\whisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "output = model.transcribe('2_min_paper_example.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aef4e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T12:00:22.822845Z",
     "start_time": "2023-01-01T12:00:22.790804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" And these fellow scholars, this is two minute papers with Dr. Karo Joel Naifahir. Today we are going to have a look at Nvidia's new AI research work, which, as they say, allows us to paint with words. So, let's see. Yes, this runs a generative denoising process, or in other words, it starts out from a bunch of noise and, over time, uses our text prompt to rearrange it into an image that we described. Great. And then, it subjects these course images to a super-resolution technique, which means that in goes this course image and out comes an image with so much more detail. And hence, it can generate images of this quality. Now, wait a minute. We are experienced fellow scholars over here, so we know that open AI's Dolly II can do this. And Google's image can do this. The free and open source stable diffusion can also do this. So, we have a number of papers that can pull this off really well. So, is Nvidia a little late to the party? Why publish this paper? What is new here? Well, let's push it to its limits through three really fun experiments and find out together. One, it gives us something that many of us fellow scholars desire. And that is, of course, more control over the synthesized images. For instance, here we wish to create an image of boxing squirrels. Yes, you heard it right, but wait, here is the more granular control part. We can draw exactly where each squirrel and the boxing gloves go. And there we go, loving it. Or if we wish to create a rabbit who is also a magician, we can also specify that it should stand on clouds and we noted that it should cast a fireball. Now, we can tell it where exactly that fireball should go. Two, it also follows our instructions really well when it comes to requesting styles as well. We can ask it to paint this penguin in the style of many famous artists with really cool results. However, sometimes just saying which artist we are looking for is not that helpful. You know, which phase of the artist are we talking about? Or which particular work should it be based on? And hold on to your papers because this can help even when our words fail us. How? Well, in this case, we can also use an image instead. We can still add a text prompt and it will create a new image in the style of this one. This is especially useful in cases when we have a style in mind that is really hard to explain. I love this one. So cool. Three, so how does it compare to the usual suspects? Well, let's have a look at some teapots. Of course, to the surprise of no one, stable diffusion and dolly too are both capable of this task. However, look, we did not get a painting of a panda. And with the new technique, look at that. Oh yes, once again, it follows our instructions better. Now, note that text to image AIs are not easy to evaluate as all models can generate a ton of different images for the same prompt. However, further comparisons reveal that there indeed is a pattern here. Now, have you noticed there is a pattern in this video too? I keep saying that this new technique follows our instructions better. So here is the most important question. Why? How is all this wizardry possible? Well, this was one of my favorite parts of the paper. Have a look at this. The authors claim that as the classical text to image AIs start out from noise, they follow our prompt closely. However, later on in the image synthesis process, not so much. If we change the prompt for the last few percentage of the noise diffusion process, look. Ouch. It completely ignores it. And here comes the best part. The authors trained multiple, separate the noise networks that are suited to different parts of the generation process. Hence, yes, you guys did right. These can follow our instructions better throughout later parts of the image generation process. And thus, give us better artistic control. Now, I am sure that the next generation of text to image AIs are going to be even more powerful, two more papers down the line. But this concept may live on to improve even these subsequent versions. I am very excited to see if this will really be the case. What a time to be alive. If you're looking for inexpensive cloud GPUs for AI, Lambda now offers the best prices in the world for GPU cloud compute. No commitments or negotiation required. Just sign up and launch an instance. And hold onto your papers because with Lambda GPU cloud, you can get on demand A100 instances for $1.10 per hour versus $4.10 per hour with AWS. That's 73% savings. Did I mention they also offer persistent storage? So join researchers at organizations like Apple, MIT and Caltech in using Lambda Cloud instances, workstations or servers. Make sure to go to LambdaLabs.com slash papers to sign up for one of their amazing GPU instances today. Thanks for watching and for your generous support. And I'll see you next time.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41519707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T12:01:12.412369Z",
     "start_time": "2023-01-01T12:01:12.371951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'seek': 0, 'start': 0.0, 'end': 4.72, 'text': ' And these fellow scholars, this is two minute papers with Dr. Karo Joel Naifahir.', 'tokens': [400, 613, 7177, 8553, 11, 341, 307, 732, 3456, 10577, 365, 2491, 13, 8009, 78, 21522, 6056, 351, 545, 347, 13], 'temperature': 0.0, 'avg_logprob': -0.25187299728393553, 'compression_ratio': 1.4936708860759493, 'no_speech_prob': 0.023671014234423637}\n",
      "0\n",
      "{'id': 1, 'seek': 0, 'start': 4.72, 'end': 11.040000000000001, 'text': \" Today we are going to have a look at Nvidia's new AI research work, which, as they say,\", 'tokens': [2692, 321, 366, 516, 281, 362, 257, 574, 412, 46284, 311, 777, 7318, 2132, 589, 11, 597, 11, 382, 436, 584, 11], 'temperature': 0.0, 'avg_logprob': -0.25187299728393553, 'compression_ratio': 1.4936708860759493, 'no_speech_prob': 0.023671014234423637}\n",
      "0\n",
      "{'id': 2, 'seek': 0, 'start': 11.040000000000001, 'end': 19.44, 'text': \" allows us to paint with words. So, let's see. Yes, this runs a generative denoising process,\", 'tokens': [4045, 505, 281, 4225, 365, 2283, 13, 407, 11, 718, 311, 536, 13, 1079, 11, 341, 6676, 257, 1337, 1166, 1441, 78, 3436, 1399, 11], 'temperature': 0.0, 'avg_logprob': -0.25187299728393553, 'compression_ratio': 1.4936708860759493, 'no_speech_prob': 0.023671014234423637}\n",
      "10\n",
      "{'id': 3, 'seek': 0, 'start': 19.44, 'end': 26.64, 'text': ' or in other words, it starts out from a bunch of noise and, over time, uses our text prompt', 'tokens': [420, 294, 661, 2283, 11, 309, 3719, 484, 490, 257, 3840, 295, 5658, 293, 11, 670, 565, 11, 4960, 527, 2487, 12391], 'temperature': 0.0, 'avg_logprob': -0.25187299728393553, 'compression_ratio': 1.4936708860759493, 'no_speech_prob': 0.023671014234423637}\n",
      "15\n",
      "{'id': 4, 'seek': 2664, 'start': 26.64, 'end': 33.44, 'text': ' to rearrange it into an image that we described. Great. And then, it subjects these course images', 'tokens': [281, 39568, 309, 666, 364, 3256, 300, 321, 7619, 13, 3769, 13, 400, 550, 11, 309, 13066, 613, 1164, 5267], 'temperature': 0.0, 'avg_logprob': -0.14163487680842368, 'compression_ratio': 1.58008658008658, 'no_speech_prob': 0.0006964706117287278}\n",
      "25\n",
      "{'id': 5, 'seek': 2664, 'start': 33.44, 'end': 39.52, 'text': ' to a super-resolution technique, which means that in goes this course image and out comes an', 'tokens': [281, 257, 1687, 12, 495, 3386, 6532, 11, 597, 1355, 300, 294, 1709, 341, 1164, 3256, 293, 484, 1487, 364], 'temperature': 0.0, 'avg_logprob': -0.14163487680842368, 'compression_ratio': 1.58008658008658, 'no_speech_prob': 0.0006964706117287278}\n",
      "30\n",
      "{'id': 6, 'seek': 2664, 'start': 39.52, 'end': 45.28, 'text': ' image with so much more detail. And hence, it can generate images of this quality.', 'tokens': [3256, 365, 370, 709, 544, 2607, 13, 400, 16678, 11, 309, 393, 8460, 5267, 295, 341, 3125, 13], 'temperature': 0.0, 'avg_logprob': -0.14163487680842368, 'compression_ratio': 1.58008658008658, 'no_speech_prob': 0.0006964706117287278}\n",
      "35\n",
      "{'id': 7, 'seek': 2664, 'start': 45.92, 'end': 52.96, 'text': \" Now, wait a minute. We are experienced fellow scholars over here, so we know that open AI's\", 'tokens': [823, 11, 1699, 257, 3456, 13, 492, 366, 6751, 7177, 8553, 670, 510, 11, 370, 321, 458, 300, 1269, 7318, 311], 'temperature': 0.0, 'avg_logprob': -0.14163487680842368, 'compression_ratio': 1.58008658008658, 'no_speech_prob': 0.0006964706117287278}\n",
      "45\n",
      "{'id': 8, 'seek': 5296, 'start': 52.96, 'end': 60.88, 'text': \" Dolly II can do this. And Google's image can do this. The free and open source stable diffusion\", 'tokens': [1144, 13020, 6351, 393, 360, 341, 13, 400, 3329, 311, 3256, 393, 360, 341, 13, 440, 1737, 293, 1269, 4009, 8351, 25242], 'temperature': 0.0, 'avg_logprob': -0.11474260917076698, 'compression_ratio': 1.4947368421052631, 'no_speech_prob': 0.0011705922661349177}\n",
      "50\n",
      "{'id': 9, 'seek': 5296, 'start': 60.88, 'end': 68.0, 'text': ' can also do this. So, we have a number of papers that can pull this off really well. So,', 'tokens': [393, 611, 360, 341, 13, 407, 11, 321, 362, 257, 1230, 295, 10577, 300, 393, 2235, 341, 766, 534, 731, 13, 407, 11], 'temperature': 0.0, 'avg_logprob': -0.11474260917076698, 'compression_ratio': 1.4947368421052631, 'no_speech_prob': 0.0011705922661349177}\n",
      "60\n",
      "{'id': 10, 'seek': 5296, 'start': 68.0, 'end': 75.76, 'text': \" is Nvidia a little late to the party? Why publish this paper? What is new here? Well, let's push it\", 'tokens': [307, 46284, 257, 707, 3469, 281, 264, 3595, 30, 1545, 11374, 341, 3035, 30, 708, 307, 777, 510, 30, 1042, 11, 718, 311, 2944, 309], 'temperature': 0.0, 'avg_logprob': -0.11474260917076698, 'compression_ratio': 1.4947368421052631, 'no_speech_prob': 0.0011705922661349177}\n",
      "65\n",
      "{'id': 11, 'seek': 7576, 'start': 75.76, 'end': 83.2, 'text': ' to its limits through three really fun experiments and find out together. One, it gives us something', 'tokens': [281, 1080, 10406, 807, 1045, 534, 1019, 12050, 293, 915, 484, 1214, 13, 1485, 11, 309, 2709, 505, 746], 'temperature': 0.0, 'avg_logprob': -0.07584428787231445, 'compression_ratio': 1.583673469387755, 'no_speech_prob': 3.055669367313385e-05}\n",
      "75\n",
      "{'id': 12, 'seek': 7576, 'start': 83.2, 'end': 90.16000000000001, 'text': ' that many of us fellow scholars desire. And that is, of course, more control over the synthesized', 'tokens': [300, 867, 295, 505, 7177, 8553, 7516, 13, 400, 300, 307, 11, 295, 1164, 11, 544, 1969, 670, 264, 26617, 1602], 'temperature': 0.0, 'avg_logprob': -0.07584428787231445, 'compression_ratio': 1.583673469387755, 'no_speech_prob': 3.055669367313385e-05}\n",
      "80\n",
      "{'id': 13, 'seek': 7576, 'start': 90.16000000000001, 'end': 98.0, 'text': ' images. For instance, here we wish to create an image of boxing squirrels. Yes, you heard it right,', 'tokens': [5267, 13, 1171, 5197, 11, 510, 321, 3172, 281, 1884, 364, 3256, 295, 24424, 28565, 82, 13, 1079, 11, 291, 2198, 309, 558, 11], 'temperature': 0.0, 'avg_logprob': -0.07584428787231445, 'compression_ratio': 1.583673469387755, 'no_speech_prob': 3.055669367313385e-05}\n",
      "90\n",
      "{'id': 14, 'seek': 7576, 'start': 98.0, 'end': 104.96000000000001, 'text': ' but wait, here is the more granular control part. We can draw exactly where each squirrel', 'tokens': [457, 1699, 11, 510, 307, 264, 544, 39962, 1969, 644, 13, 492, 393, 2642, 2293, 689, 1184, 28565], 'temperature': 0.0, 'avg_logprob': -0.07584428787231445, 'compression_ratio': 1.583673469387755, 'no_speech_prob': 3.055669367313385e-05}\n",
      "95\n",
      "{'id': 15, 'seek': 10496, 'start': 104.96, 'end': 113.11999999999999, 'text': ' and the boxing gloves go. And there we go, loving it. Or if we wish to create a rabbit who is also', 'tokens': [293, 264, 24424, 14976, 352, 13, 400, 456, 321, 352, 11, 9344, 309, 13, 1610, 498, 321, 3172, 281, 1884, 257, 19509, 567, 307, 611], 'temperature': 0.0, 'avg_logprob': -0.07880696070562933, 'compression_ratio': 1.6754385964912282, 'no_speech_prob': 0.00020443032553885132}\n",
      "100\n",
      "{'id': 16, 'seek': 10496, 'start': 113.11999999999999, 'end': 119.83999999999999, 'text': ' a magician, we can also specify that it should stand on clouds and we noted that it should cast', 'tokens': [257, 38614, 11, 321, 393, 611, 16500, 300, 309, 820, 1463, 322, 12193, 293, 321, 12964, 300, 309, 820, 4193], 'temperature': 0.0, 'avg_logprob': -0.07880696070562933, 'compression_ratio': 1.6754385964912282, 'no_speech_prob': 0.00020443032553885132}\n",
      "110\n",
      "{'id': 17, 'seek': 10496, 'start': 119.83999999999999, 'end': 127.91999999999999, 'text': ' a fireball. Now, we can tell it where exactly that fireball should go. Two, it also follows our', 'tokens': [257, 2610, 3129, 13, 823, 11, 321, 393, 980, 309, 689, 2293, 300, 2610, 3129, 820, 352, 13, 4453, 11, 309, 611, 10002, 527], 'temperature': 0.0, 'avg_logprob': -0.07880696070562933, 'compression_ratio': 1.6754385964912282, 'no_speech_prob': 0.00020443032553885132}\n",
      "115\n",
      "{'id': 18, 'seek': 10496, 'start': 127.91999999999999, 'end': 134.4, 'text': ' instructions really well when it comes to requesting styles as well. We can ask it to paint', 'tokens': [9415, 534, 731, 562, 309, 1487, 281, 31937, 13273, 382, 731, 13, 492, 393, 1029, 309, 281, 4225], 'temperature': 0.0, 'avg_logprob': -0.07880696070562933, 'compression_ratio': 1.6754385964912282, 'no_speech_prob': 0.00020443032553885132}\n",
      "125\n",
      "{'id': 19, 'seek': 13440, 'start': 134.4, 'end': 141.04000000000002, 'text': ' this penguin in the style of many famous artists with really cool results. However,', 'tokens': [341, 45752, 294, 264, 3758, 295, 867, 4618, 6910, 365, 534, 1627, 3542, 13, 2908, 11], 'temperature': 0.0, 'avg_logprob': -0.09125690026716753, 'compression_ratio': 1.5683760683760684, 'no_speech_prob': 0.00011028705921489745}\n",
      "130\n",
      "{'id': 20, 'seek': 13440, 'start': 141.04000000000002, 'end': 147.12, 'text': ' sometimes just saying which artist we are looking for is not that helpful. You know, which', 'tokens': [2171, 445, 1566, 597, 5748, 321, 366, 1237, 337, 307, 406, 300, 4961, 13, 509, 458, 11, 597], 'temperature': 0.0, 'avg_logprob': -0.09125690026716753, 'compression_ratio': 1.5683760683760684, 'no_speech_prob': 0.00011028705921489745}\n",
      "140\n",
      "{'id': 21, 'seek': 13440, 'start': 147.12, 'end': 153.84, 'text': ' phase of the artist are we talking about? Or which particular work should it be based on? And', 'tokens': [5574, 295, 264, 5748, 366, 321, 1417, 466, 30, 1610, 597, 1729, 589, 820, 309, 312, 2361, 322, 30, 400], 'temperature': 0.0, 'avg_logprob': -0.09125690026716753, 'compression_ratio': 1.5683760683760684, 'no_speech_prob': 0.00011028705921489745}\n",
      "145\n",
      "{'id': 22, 'seek': 13440, 'start': 153.84, 'end': 161.28, 'text': ' hold on to your papers because this can help even when our words fail us. How? Well, in this case,', 'tokens': [1797, 322, 281, 428, 10577, 570, 341, 393, 854, 754, 562, 527, 2283, 3061, 505, 13, 1012, 30, 1042, 11, 294, 341, 1389, 11], 'temperature': 0.0, 'avg_logprob': -0.09125690026716753, 'compression_ratio': 1.5683760683760684, 'no_speech_prob': 0.00011028705921489745}\n",
      "150\n",
      "{'id': 23, 'seek': 16128, 'start': 161.28, 'end': 168.8, 'text': ' we can also use an image instead. We can still add a text prompt and it will create a new image', 'tokens': [321, 393, 611, 764, 364, 3256, 2602, 13, 492, 393, 920, 909, 257, 2487, 12391, 293, 309, 486, 1884, 257, 777, 3256], 'temperature': 0.0, 'avg_logprob': -0.08052570978800455, 'compression_ratio': 1.5543478260869565, 'no_speech_prob': 0.0001850252301665023}\n",
      "160\n",
      "{'id': 24, 'seek': 16128, 'start': 168.8, 'end': 176.48, 'text': ' in the style of this one. This is especially useful in cases when we have a style in mind that is', 'tokens': [294, 264, 3758, 295, 341, 472, 13, 639, 307, 2318, 4420, 294, 3331, 562, 321, 362, 257, 3758, 294, 1575, 300, 307], 'temperature': 0.0, 'avg_logprob': -0.08052570978800455, 'compression_ratio': 1.5543478260869565, 'no_speech_prob': 0.0001850252301665023}\n",
      "165\n",
      "{'id': 25, 'seek': 16128, 'start': 176.48, 'end': 184.24, 'text': ' really hard to explain. I love this one. So cool. Three, so how does it compare to the usual', 'tokens': [534, 1152, 281, 2903, 13, 286, 959, 341, 472, 13, 407, 1627, 13, 6244, 11, 370, 577, 775, 309, 6794, 281, 264, 7713], 'temperature': 0.0, 'avg_logprob': -0.08052570978800455, 'compression_ratio': 1.5543478260869565, 'no_speech_prob': 0.0001850252301665023}\n",
      "175\n",
      "{'id': 26, 'seek': 18424, 'start': 184.24, 'end': 191.60000000000002, 'text': \" suspects? Well, let's have a look at some teapots. Of course, to the surprise of no one, stable\", 'tokens': [35667, 30, 1042, 11, 718, 311, 362, 257, 574, 412, 512, 535, 569, 1971, 13, 2720, 1164, 11, 281, 264, 6365, 295, 572, 472, 11, 8351], 'temperature': 0.0, 'avg_logprob': -0.11831142832931962, 'compression_ratio': 1.5317460317460319, 'no_speech_prob': 0.00019293715013191104}\n",
      "180\n",
      "{'id': 27, 'seek': 18424, 'start': 191.60000000000002, 'end': 198.96, 'text': ' diffusion and dolly too are both capable of this task. However, look, we did not get a painting', 'tokens': [25242, 293, 360, 13020, 886, 366, 1293, 8189, 295, 341, 5633, 13, 2908, 11, 574, 11, 321, 630, 406, 483, 257, 5370], 'temperature': 0.0, 'avg_logprob': -0.11831142832931962, 'compression_ratio': 1.5317460317460319, 'no_speech_prob': 0.00019293715013191104}\n",
      "190\n",
      "{'id': 28, 'seek': 18424, 'start': 198.96, 'end': 207.04000000000002, 'text': ' of a panda. And with the new technique, look at that. Oh yes, once again, it follows our instructions', 'tokens': [295, 257, 46685, 13, 400, 365, 264, 777, 6532, 11, 574, 412, 300, 13, 876, 2086, 11, 1564, 797, 11, 309, 10002, 527, 9415], 'temperature': 0.0, 'avg_logprob': -0.11831142832931962, 'compression_ratio': 1.5317460317460319, 'no_speech_prob': 0.00019293715013191104}\n",
      "195\n",
      "{'id': 29, 'seek': 18424, 'start': 207.04000000000002, 'end': 214.0, 'text': ' better. Now, note that text to image AIs are not easy to evaluate as all models can generate', 'tokens': [1101, 13, 823, 11, 3637, 300, 2487, 281, 3256, 316, 6802, 366, 406, 1858, 281, 13059, 382, 439, 5245, 393, 8460], 'temperature': 0.0, 'avg_logprob': -0.11831142832931962, 'compression_ratio': 1.5317460317460319, 'no_speech_prob': 0.00019293715013191104}\n",
      "205\n",
      "{'id': 30, 'seek': 21400, 'start': 214.0, 'end': 220.24, 'text': ' a ton of different images for the same prompt. However, further comparisons reveal that there', 'tokens': [257, 2952, 295, 819, 5267, 337, 264, 912, 12391, 13, 2908, 11, 3052, 33157, 10658, 300, 456], 'temperature': 0.0, 'avg_logprob': -0.09965682559543186, 'compression_ratio': 1.606694560669456, 'no_speech_prob': 0.00013274834782350808}\n",
      "210\n",
      "{'id': 31, 'seek': 21400, 'start': 220.24, 'end': 228.0, 'text': ' indeed is a pattern here. Now, have you noticed there is a pattern in this video too? I keep saying', 'tokens': [6451, 307, 257, 5102, 510, 13, 823, 11, 362, 291, 5694, 456, 307, 257, 5102, 294, 341, 960, 886, 30, 286, 1066, 1566], 'temperature': 0.0, 'avg_logprob': -0.09965682559543186, 'compression_ratio': 1.606694560669456, 'no_speech_prob': 0.00013274834782350808}\n",
      "220\n",
      "{'id': 32, 'seek': 21400, 'start': 228.0, 'end': 234.72, 'text': ' that this new technique follows our instructions better. So here is the most important question.', 'tokens': [300, 341, 777, 6532, 10002, 527, 9415, 1101, 13, 407, 510, 307, 264, 881, 1021, 1168, 13], 'temperature': 0.0, 'avg_logprob': -0.09965682559543186, 'compression_ratio': 1.606694560669456, 'no_speech_prob': 0.00013274834782350808}\n",
      "225\n",
      "{'id': 33, 'seek': 21400, 'start': 234.72, 'end': 242.24, 'text': ' Why? How is all this wizardry possible? Well, this was one of my favorite parts of the paper.', 'tokens': [1545, 30, 1012, 307, 439, 341, 25807, 627, 1944, 30, 1042, 11, 341, 390, 472, 295, 452, 2954, 3166, 295, 264, 3035, 13], 'temperature': 0.0, 'avg_logprob': -0.09965682559543186, 'compression_ratio': 1.606694560669456, 'no_speech_prob': 0.00013274834782350808}\n",
      "230\n",
      "{'id': 34, 'seek': 24224, 'start': 242.24, 'end': 249.60000000000002, 'text': ' Have a look at this. The authors claim that as the classical text to image AIs start out from noise,', 'tokens': [3560, 257, 574, 412, 341, 13, 440, 16552, 3932, 300, 382, 264, 13735, 2487, 281, 3256, 316, 6802, 722, 484, 490, 5658, 11], 'temperature': 0.0, 'avg_logprob': -0.1158689456981617, 'compression_ratio': 1.6180257510729614, 'no_speech_prob': 0.00013576469791587442}\n",
      "240\n",
      "{'id': 35, 'seek': 24224, 'start': 249.60000000000002, 'end': 256.96000000000004, 'text': ' they follow our prompt closely. However, later on in the image synthesis process, not so much.', 'tokens': [436, 1524, 527, 12391, 8185, 13, 2908, 11, 1780, 322, 294, 264, 3256, 30252, 1399, 11, 406, 370, 709, 13], 'temperature': 0.0, 'avg_logprob': -0.1158689456981617, 'compression_ratio': 1.6180257510729614, 'no_speech_prob': 0.00013576469791587442}\n",
      "245\n",
      "{'id': 36, 'seek': 24224, 'start': 256.96000000000004, 'end': 262.08, 'text': ' If we change the prompt for the last few percentage of the noise diffusion process, look.', 'tokens': [759, 321, 1319, 264, 12391, 337, 264, 1036, 1326, 9668, 295, 264, 5658, 25242, 1399, 11, 574, 13], 'temperature': 0.0, 'avg_logprob': -0.1158689456981617, 'compression_ratio': 1.6180257510729614, 'no_speech_prob': 0.00013576469791587442}\n",
      "255\n",
      "{'id': 37, 'seek': 24224, 'start': 262.8, 'end': 270.08, 'text': ' Ouch. It completely ignores it. And here comes the best part. The authors trained multiple,', 'tokens': [27217, 13, 467, 2584, 5335, 2706, 309, 13, 400, 510, 1487, 264, 1151, 644, 13, 440, 16552, 8895, 3866, 11], 'temperature': 0.0, 'avg_logprob': -0.1158689456981617, 'compression_ratio': 1.6180257510729614, 'no_speech_prob': 0.00013576469791587442}\n",
      "260\n",
      "{'id': 38, 'seek': 27008, 'start': 270.08, 'end': 276.32, 'text': ' separate the noise networks that are suited to different parts of the generation process.', 'tokens': [4994, 264, 5658, 9590, 300, 366, 24736, 281, 819, 3166, 295, 264, 5125, 1399, 13], 'temperature': 0.0, 'avg_logprob': -0.11493275586296531, 'compression_ratio': 1.669603524229075, 'no_speech_prob': 0.00024020459386520088}\n",
      "270\n",
      "{'id': 39, 'seek': 27008, 'start': 276.32, 'end': 283.03999999999996, 'text': ' Hence, yes, you guys did right. These can follow our instructions better throughout later parts', 'tokens': [22229, 11, 2086, 11, 291, 1074, 630, 558, 13, 1981, 393, 1524, 527, 9415, 1101, 3710, 1780, 3166], 'temperature': 0.0, 'avg_logprob': -0.11493275586296531, 'compression_ratio': 1.669603524229075, 'no_speech_prob': 0.00024020459386520088}\n",
      "275\n",
      "{'id': 40, 'seek': 27008, 'start': 283.03999999999996, 'end': 289.76, 'text': ' of the image generation process. And thus, give us better artistic control. Now, I am sure that', 'tokens': [295, 264, 3256, 5125, 1399, 13, 400, 8807, 11, 976, 505, 1101, 17090, 1969, 13, 823, 11, 286, 669, 988, 300], 'temperature': 0.0, 'avg_logprob': -0.11493275586296531, 'compression_ratio': 1.669603524229075, 'no_speech_prob': 0.00024020459386520088}\n",
      "280\n",
      "{'id': 41, 'seek': 27008, 'start': 289.76, 'end': 296.08, 'text': ' the next generation of text to image AIs are going to be even more powerful, two more papers down', 'tokens': [264, 958, 5125, 295, 2487, 281, 3256, 316, 6802, 366, 516, 281, 312, 754, 544, 4005, 11, 732, 544, 10577, 760], 'temperature': 0.0, 'avg_logprob': -0.11493275586296531, 'compression_ratio': 1.669603524229075, 'no_speech_prob': 0.00024020459386520088}\n",
      "285\n",
      "{'id': 42, 'seek': 29608, 'start': 296.08, 'end': 303.84, 'text': ' the line. But this concept may live on to improve even these subsequent versions. I am very excited', 'tokens': [264, 1622, 13, 583, 341, 3410, 815, 1621, 322, 281, 3470, 754, 613, 19962, 9606, 13, 286, 669, 588, 2919], 'temperature': 0.0, 'avg_logprob': -0.11378228533398974, 'compression_ratio': 1.5138339920948616, 'no_speech_prob': 0.00042578793363645673}\n",
      "295\n",
      "{'id': 43, 'seek': 29608, 'start': 303.84, 'end': 310.08, 'text': \" to see if this will really be the case. What a time to be alive. If you're looking for inexpensive\", 'tokens': [281, 536, 498, 341, 486, 534, 312, 264, 1389, 13, 708, 257, 565, 281, 312, 5465, 13, 759, 291, 434, 1237, 337, 28382], 'temperature': 0.0, 'avg_logprob': -0.11378228533398974, 'compression_ratio': 1.5138339920948616, 'no_speech_prob': 0.00042578793363645673}\n",
      "300\n",
      "{'id': 44, 'seek': 29608, 'start': 310.08, 'end': 318.47999999999996, 'text': ' cloud GPUs for AI, Lambda now offers the best prices in the world for GPU cloud compute.', 'tokens': [4588, 18407, 82, 337, 7318, 11, 45691, 586, 7736, 264, 1151, 7901, 294, 264, 1002, 337, 18407, 4588, 14722, 13], 'temperature': 0.0, 'avg_logprob': -0.11378228533398974, 'compression_ratio': 1.5138339920948616, 'no_speech_prob': 0.00042578793363645673}\n",
      "310\n",
      "{'id': 45, 'seek': 29608, 'start': 318.47999999999996, 'end': 325.68, 'text': ' No commitments or negotiation required. Just sign up and launch an instance. And hold onto your', 'tokens': [883, 26230, 420, 27573, 4739, 13, 1449, 1465, 493, 293, 4025, 364, 5197, 13, 400, 1797, 3911, 428], 'temperature': 0.0, 'avg_logprob': -0.11378228533398974, 'compression_ratio': 1.5138339920948616, 'no_speech_prob': 0.00042578793363645673}\n",
      "315\n",
      "{'id': 46, 'seek': 32568, 'start': 325.68, 'end': 335.52, 'text': ' papers because with Lambda GPU cloud, you can get on demand A100 instances for $1.10 per hour versus', 'tokens': [10577, 570, 365, 45691, 18407, 4588, 11, 291, 393, 483, 322, 4733, 316, 6879, 14519, 337, 1848, 16, 13, 3279, 680, 1773, 5717], 'temperature': 0.0, 'avg_logprob': -0.14422576068198845, 'compression_ratio': 1.3691588785046729, 'no_speech_prob': 0.00022795848781242967}\n",
      "325\n",
      "{'id': 47, 'seek': 32568, 'start': 335.52, 'end': 345.12, 'text': \" $4.10 per hour with AWS. That's 73% savings. Did I mention they also offer persistent storage?\", 'tokens': [1848, 19, 13, 3279, 680, 1773, 365, 17650, 13, 663, 311, 28387, 4, 13454, 13, 2589, 286, 2152, 436, 611, 2626, 24315, 6725, 30], 'temperature': 0.0, 'avg_logprob': -0.14422576068198845, 'compression_ratio': 1.3691588785046729, 'no_speech_prob': 0.00022795848781242967}\n",
      "335\n",
      "{'id': 48, 'seek': 32568, 'start': 345.12, 'end': 353.28000000000003, 'text': ' So join researchers at organizations like Apple, MIT and Caltech in using Lambda Cloud instances,', 'tokens': [407, 3917, 10309, 412, 6150, 411, 6373, 11, 13100, 293, 3511, 25970, 294, 1228, 45691, 8061, 14519, 11], 'temperature': 0.0, 'avg_logprob': -0.14422576068198845, 'compression_ratio': 1.3691588785046729, 'no_speech_prob': 0.00022795848781242967}\n",
      "345\n",
      "{'id': 49, 'seek': 35328, 'start': 353.28, 'end': 361.11999999999995, 'text': ' workstations or servers. Make sure to go to LambdaLabs.com slash papers to sign up for one of their', 'tokens': [589, 372, 763, 420, 15909, 13, 4387, 988, 281, 352, 281, 45691, 43, 17243, 13, 1112, 17330, 10577, 281, 1465, 493, 337, 472, 295, 641], 'temperature': 0.0, 'avg_logprob': -0.21223174608670747, 'compression_ratio': 1.3018867924528301, 'no_speech_prob': 0.00022916086891200393}\n",
      "350\n",
      "{'id': 50, 'seek': 36112, 'start': 361.12, 'end': 390.96, 'text': \" amazing GPU instances today. Thanks for watching and for your generous support. And I'll see you next time.\", 'tokens': [50364, 2243, 18407, 14519, 965, 13, 2561, 337, 1976, 293, 337, 428, 14537, 1406, 13, 400, 286, 603, 536, 291, 958, 565, 13, 51856], 'temperature': 0.0, 'avg_logprob': -0.21550180435180663, 'compression_ratio': 1.0918367346938775, 'no_speech_prob': 4.246918615535833e-05}\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "for segment in output['segments']:\n",
    "  print(segment)\n",
    "  second = int(segment['start'])\n",
    "  second = second - (second % 5)\n",
    "  print(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b0f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
